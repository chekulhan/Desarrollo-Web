Adicional:

```python
from transformers import pipeline
from datasets import Dataset, Audio
import soundfile as sf

# Load the Spanish ASR model
asr = pipeline("automatic-speech-recognition", model="facebook/wav2vec2-large-xlsr-53-spanish")

# Load the audio file (replace 'path_to_audio_file' with the actual path to your file)
audio_file = 'path_to_audio_file.wav'
audio_data, sample_rate = sf.read(audio_file)

# Make sure the audio file is in the right format
audio_input = {"audio": {"array": audio_data, "sampling_rate": sample_rate}}

# Create a dataset from the audio input
dataset = Dataset.from_dict(audio_input)

# Process the audio through the ASR pipeline
texts = asr(dataset["audio"])

# Print the transcription
print(texts[0]["text"])
```



SAVE model:

```python
from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor

# Load the model and processor
model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-large-xlsr-53-spanish")
processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-large-xlsr-53-spanish")

# Save the model and processor locally
model.save_pretrained('./saved_model')
processor.save_pretrained('./saved_model')
```